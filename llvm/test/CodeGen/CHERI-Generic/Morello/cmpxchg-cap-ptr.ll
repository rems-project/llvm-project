; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --function-signature --scrub-attributes --force-update
; DO NOT EDIT -- This file was generated from test/CodeGen/CHERI-Generic/Inputs/cmpxchg-cap-ptr.ll
; Check that we can generate sensible code for atomic operations using capability pointers on capabilities
; in both hybrid and purecap mode.
; See https://github.com/CTSRD-CHERI/llvm-project/issues/470
; RUN: llc -mtriple=aarch64 --relocation-model=pic -target-abi purecap -mattr=+morello,+c64 < %s | FileCheck %s --check-prefix=PURECAP
; RUN: llc -mtriple=aarch64 --relocation-model=pic -target-abi aapcs -mattr=+morello,-c64 < %s | FileCheck %s --check-prefix=HYBRID

define { i8, i1 } @test_cmpxchg_strong_i8(i8 addrspace(200)* %ptr, i8 %exp, i8 %new) nounwind {
; PURECAP-LABEL: test_cmpxchg_strong_i8:
; PURECAP:       .Lfunc_begin0:
; PURECAP-NEXT:  // %bb.0:
; PURECAP-NEXT:    mov c3, c0
; PURECAP-NEXT:    // kill: def $w2 killed $w2 def $x2
; PURECAP-NEXT:  .LBB0_1: // %cmpxchg.start
; PURECAP-NEXT:    // =>This Inner Loop Header: Depth=1
; PURECAP-NEXT:    ldaxrb w0, [c3]
; PURECAP-NEXT:    cmp w0, w1, uxtb
; PURECAP-NEXT:    b.ne .LBB0_4
; PURECAP-NEXT:  // %bb.2: // %cmpxchg.trystore
; PURECAP-NEXT:    // in Loop: Header=BB0_1 Depth=1
; PURECAP-NEXT:    stlxrb w8, w2, [c3]
; PURECAP-NEXT:    cbnz w8, .LBB0_1
; PURECAP-NEXT:  // %bb.3:
; PURECAP-NEXT:    mov w1, #1
; PURECAP-NEXT:    // kill: def $w0 killed $w0 killed $x0
; PURECAP-NEXT:    ret c30
; PURECAP-NEXT:  .LBB0_4: // %cmpxchg.nostore
; PURECAP-NEXT:    clrex
; PURECAP-NEXT:    mov w1, wzr
; PURECAP-NEXT:    // kill: def $w0 killed $w0 killed $x0
; PURECAP-NEXT:    ret c30
;
; HYBRID-LABEL: test_cmpxchg_strong_i8:
; HYBRID:       // %bb.0:
; HYBRID-NEXT:    stp x30, x19, [sp, #-16]! // 16-byte Folded Spill
; HYBRID-NEXT:    mov w19, w1
; HYBRID-NEXT:    bl __sync_val_compare_and_swap_1_c
; HYBRID-NEXT:    cmp w0, w19, uxtb
; HYBRID-NEXT:    cset w1, eq
; HYBRID-NEXT:    ldp x30, x19, [sp], #16 // 16-byte Folded Reload
; HYBRID-NEXT:    ret
  %1 = cmpxchg i8 addrspace(200)* %ptr, i8 %exp, i8 %new acq_rel acquire
  ret { i8, i1 } %1
}

define { i16, i1 } @test_cmpxchg_strong_i16(i16 addrspace(200)* %ptr, i16 %exp, i16 %new) nounwind {
; PURECAP-LABEL: test_cmpxchg_strong_i16:
; PURECAP:       .Lfunc_begin1:
; PURECAP-NEXT:  // %bb.0:
; PURECAP-NEXT:    mov c3, c0
; PURECAP-NEXT:    // kill: def $w2 killed $w2 def $x2
; PURECAP-NEXT:  .LBB1_1: // %cmpxchg.start
; PURECAP-NEXT:    // =>This Inner Loop Header: Depth=1
; PURECAP-NEXT:    ldaxrh w0, [c3]
; PURECAP-NEXT:    cmp w0, w1, uxth
; PURECAP-NEXT:    b.ne .LBB1_4
; PURECAP-NEXT:  // %bb.2: // %cmpxchg.trystore
; PURECAP-NEXT:    // in Loop: Header=BB1_1 Depth=1
; PURECAP-NEXT:    stlxrh w8, w2, [c3]
; PURECAP-NEXT:    cbnz w8, .LBB1_1
; PURECAP-NEXT:  // %bb.3:
; PURECAP-NEXT:    mov w1, #1
; PURECAP-NEXT:    // kill: def $w0 killed $w0 killed $x0
; PURECAP-NEXT:    ret c30
; PURECAP-NEXT:  .LBB1_4: // %cmpxchg.nostore
; PURECAP-NEXT:    clrex
; PURECAP-NEXT:    mov w1, wzr
; PURECAP-NEXT:    // kill: def $w0 killed $w0 killed $x0
; PURECAP-NEXT:    ret c30
;
; HYBRID-LABEL: test_cmpxchg_strong_i16:
; HYBRID:       // %bb.0:
; HYBRID-NEXT:    stp x30, x19, [sp, #-16]! // 16-byte Folded Spill
; HYBRID-NEXT:    mov w19, w1
; HYBRID-NEXT:    bl __sync_val_compare_and_swap_2_c
; HYBRID-NEXT:    cmp w0, w19, uxth
; HYBRID-NEXT:    cset w1, eq
; HYBRID-NEXT:    ldp x30, x19, [sp], #16 // 16-byte Folded Reload
; HYBRID-NEXT:    ret
  %1 = cmpxchg i16 addrspace(200)* %ptr, i16 %exp, i16 %new acq_rel acquire
  ret { i16, i1 } %1
}

define { i32, i1 } @test_cmpxchg_strong_i32(i32 addrspace(200)* %ptr, i32 %exp, i32 %new) nounwind {
; PURECAP-LABEL: test_cmpxchg_strong_i32:
; PURECAP:       .Lfunc_begin2:
; PURECAP-NEXT:  // %bb.0:
; PURECAP-NEXT:    mov c3, c0
; PURECAP-NEXT:  .LBB2_1: // %cmpxchg.start
; PURECAP-NEXT:    // =>This Inner Loop Header: Depth=1
; PURECAP-NEXT:    ldaxr w0, [c3]
; PURECAP-NEXT:    cmp w0, w1
; PURECAP-NEXT:    b.ne .LBB2_4
; PURECAP-NEXT:  // %bb.2: // %cmpxchg.trystore
; PURECAP-NEXT:    // in Loop: Header=BB2_1 Depth=1
; PURECAP-NEXT:    stlxr w8, w2, [c3]
; PURECAP-NEXT:    cbnz w8, .LBB2_1
; PURECAP-NEXT:  // %bb.3:
; PURECAP-NEXT:    mov w1, #1
; PURECAP-NEXT:    // kill: def $w0 killed $w0 killed $x0
; PURECAP-NEXT:    ret c30
; PURECAP-NEXT:  .LBB2_4: // %cmpxchg.nostore
; PURECAP-NEXT:    clrex
; PURECAP-NEXT:    mov w1, wzr
; PURECAP-NEXT:    // kill: def $w0 killed $w0 killed $x0
; PURECAP-NEXT:    ret c30
;
; HYBRID-LABEL: test_cmpxchg_strong_i32:
; HYBRID:       // %bb.0:
; HYBRID-NEXT:    stp x30, x19, [sp, #-16]! // 16-byte Folded Spill
; HYBRID-NEXT:    mov w19, w1
; HYBRID-NEXT:    bl __sync_val_compare_and_swap_4_c
; HYBRID-NEXT:    cmp w0, w19
; HYBRID-NEXT:    cset w1, eq
; HYBRID-NEXT:    ldp x30, x19, [sp], #16 // 16-byte Folded Reload
; HYBRID-NEXT:    ret
  %1 = cmpxchg i32 addrspace(200)* %ptr, i32 %exp, i32 %new acq_rel acquire
  ret { i32, i1 } %1
}

define { i64, i1 } @test_cmpxchg_strong_i64(i64 addrspace(200)* %ptr, i64 %exp, i64 %new) nounwind {
; PURECAP-LABEL: test_cmpxchg_strong_i64:
; PURECAP:       .Lfunc_begin3:
; PURECAP-NEXT:  // %bb.0:
; PURECAP-NEXT:    mov c3, c0
; PURECAP-NEXT:  .LBB3_1: // %cmpxchg.start
; PURECAP-NEXT:    // =>This Inner Loop Header: Depth=1
; PURECAP-NEXT:    ldaxr x0, [c3]
; PURECAP-NEXT:    cmp x0, x1
; PURECAP-NEXT:    b.ne .LBB3_4
; PURECAP-NEXT:  // %bb.2: // %cmpxchg.trystore
; PURECAP-NEXT:    // in Loop: Header=BB3_1 Depth=1
; PURECAP-NEXT:    stlxr w8, x2, [c3]
; PURECAP-NEXT:    cbnz w8, .LBB3_1
; PURECAP-NEXT:  // %bb.3:
; PURECAP-NEXT:    mov w1, #1
; PURECAP-NEXT:    ret c30
; PURECAP-NEXT:  .LBB3_4: // %cmpxchg.nostore
; PURECAP-NEXT:    clrex
; PURECAP-NEXT:    mov w1, wzr
; PURECAP-NEXT:    ret c30
;
; HYBRID-LABEL: test_cmpxchg_strong_i64:
; HYBRID:       // %bb.0:
; HYBRID-NEXT:    stp x30, x19, [sp, #-16]! // 16-byte Folded Spill
; HYBRID-NEXT:    mov x19, x1
; HYBRID-NEXT:    bl __sync_val_compare_and_swap_8_c
; HYBRID-NEXT:    cmp x0, x19
; HYBRID-NEXT:    cset w1, eq
; HYBRID-NEXT:    ldp x30, x19, [sp], #16 // 16-byte Folded Reload
; HYBRID-NEXT:    ret
  %1 = cmpxchg i64 addrspace(200)* %ptr, i64 %exp, i64 %new acq_rel acquire
  ret { i64, i1 } %1
}

define { i8 addrspace(200)*, i1 } @test_cmpxchg_strong_cap(i8 addrspace(200)* addrspace(200)* %ptr, i8 addrspace(200)* %exp, i8 addrspace(200)* %new) nounwind {
; PURECAP-LABEL: test_cmpxchg_strong_cap:
; PURECAP:       .Lfunc_begin4:
; PURECAP-NEXT:  // %bb.0:
; PURECAP-NEXT:    mov c3, c1
; PURECAP-NEXT:    casal c3, c2, [c0]
; PURECAP-NEXT:    cmp x3, x1
; PURECAP-NEXT:    cset w1, eq
; PURECAP-NEXT:    mov c0, c3
; PURECAP-NEXT:    ret c30
;
; HYBRID-LABEL: test_cmpxchg_strong_cap:
; HYBRID:       // %bb.0:
; HYBRID-NEXT:    sub sp, sp, #32 // =32
; HYBRID-NEXT:    str x30, [sp, #16] // 8-byte Folded Spill
; HYBRID-NEXT:    str c1, [sp, #0] // 16-byte Folded Spill
; HYBRID-NEXT:    bl __sync_val_compare_and_swap_cap_c
; HYBRID-NEXT:    ldr c1, [sp, #0] // 16-byte Folded Reload
; HYBRID-NEXT:    ldr x30, [sp, #16] // 8-byte Folded Reload
; HYBRID-NEXT:    cmp x0, x1
; HYBRID-NEXT:    cset w1, eq
; HYBRID-NEXT:    add sp, sp, #32 // =32
; HYBRID-NEXT:    ret
  %1 = cmpxchg i8 addrspace(200)* addrspace(200)* %ptr, i8 addrspace(200)* %exp, i8 addrspace(200)* %new acq_rel acquire
  ret { i8 addrspace(200)*, i1 } %1
}

define { i32 addrspace(200)*, i1 } @test_cmpxchg_strong_cap_i32(i32 addrspace(200)* addrspace(200)* %ptr, i32 addrspace(200)* %exp, i32 addrspace(200)* %new) nounwind {
; PURECAP-LABEL: test_cmpxchg_strong_cap_i32:
; PURECAP:       .Lfunc_begin5:
; PURECAP-NEXT:  // %bb.0:
; PURECAP-NEXT:    mov c3, c1
; PURECAP-NEXT:    casal c3, c2, [c0]
; PURECAP-NEXT:    cmp x3, x1
; PURECAP-NEXT:    cset w1, eq
; PURECAP-NEXT:    mov c0, c3
; PURECAP-NEXT:    ret c30
;
; HYBRID-LABEL: test_cmpxchg_strong_cap_i32:
; HYBRID:       // %bb.0:
; HYBRID-NEXT:    sub sp, sp, #32 // =32
; HYBRID-NEXT:    str x30, [sp, #16] // 8-byte Folded Spill
; HYBRID-NEXT:    str c1, [sp, #0] // 16-byte Folded Spill
; HYBRID-NEXT:    bl __sync_val_compare_and_swap_cap_c
; HYBRID-NEXT:    ldr c1, [sp, #0] // 16-byte Folded Reload
; HYBRID-NEXT:    ldr x30, [sp, #16] // 8-byte Folded Reload
; HYBRID-NEXT:    cmp x0, x1
; HYBRID-NEXT:    cset w1, eq
; HYBRID-NEXT:    add sp, sp, #32 // =32
; HYBRID-NEXT:    ret
  %1 = cmpxchg weak i32 addrspace(200)* addrspace(200)* %ptr, i32 addrspace(200)* %exp, i32 addrspace(200)* %new acq_rel acquire
  ret { i32 addrspace(200)*, i1 } %1
}


define { i8, i1 } @test_cmpxchg_weak_i8(i8 addrspace(200)* %ptr, i8 %exp, i8 %new) nounwind {
; PURECAP-LABEL: test_cmpxchg_weak_i8:
; PURECAP:       .Lfunc_begin6:
; PURECAP-NEXT:  // %bb.0: // %cmpxchg.start
; PURECAP-NEXT:    mov c3, c0
; PURECAP-NEXT:    ldaxrb w0, [c0]
; PURECAP-NEXT:    // kill: def $w2 killed $w2 def $x2
; PURECAP-NEXT:    cmp w0, w1, uxtb
; PURECAP-NEXT:    b.ne .LBB6_3
; PURECAP-NEXT:  // %bb.1: // %cmpxchg.trystore
; PURECAP-NEXT:    stlxrb w8, w2, [c3]
; PURECAP-NEXT:    cbz w8, .LBB6_4
; PURECAP-NEXT:  // %bb.2: // %cmpxchg.failure
; PURECAP-NEXT:    mov w1, wzr
; PURECAP-NEXT:    // kill: def $w0 killed $w0 killed $x0
; PURECAP-NEXT:    ret c30
; PURECAP-NEXT:  .LBB6_3: // %cmpxchg.nostore
; PURECAP-NEXT:    clrex
; PURECAP-NEXT:    mov w1, wzr
; PURECAP-NEXT:    // kill: def $w0 killed $w0 killed $x0
; PURECAP-NEXT:    ret c30
; PURECAP-NEXT:  .LBB6_4:
; PURECAP-NEXT:    mov w1, #1
; PURECAP-NEXT:    // kill: def $w0 killed $w0 killed $x0
; PURECAP-NEXT:    ret c30
;
; HYBRID-LABEL: test_cmpxchg_weak_i8:
; HYBRID:       // %bb.0:
; HYBRID-NEXT:    stp x30, x19, [sp, #-16]! // 16-byte Folded Spill
; HYBRID-NEXT:    mov w19, w1
; HYBRID-NEXT:    bl __sync_val_compare_and_swap_1_c
; HYBRID-NEXT:    cmp w0, w19, uxtb
; HYBRID-NEXT:    cset w1, eq
; HYBRID-NEXT:    ldp x30, x19, [sp], #16 // 16-byte Folded Reload
; HYBRID-NEXT:    ret
  %1 = cmpxchg weak i8 addrspace(200)* %ptr, i8 %exp, i8 %new acq_rel acquire
  ret { i8, i1 } %1
}

define { i16, i1 } @test_cmpxchg_weak_i16(i16 addrspace(200)* %ptr, i16 %exp, i16 %new) nounwind {
; PURECAP-LABEL: test_cmpxchg_weak_i16:
; PURECAP:       .Lfunc_begin7:
; PURECAP-NEXT:  // %bb.0: // %cmpxchg.start
; PURECAP-NEXT:    mov c3, c0
; PURECAP-NEXT:    ldaxrh w0, [c0]
; PURECAP-NEXT:    // kill: def $w2 killed $w2 def $x2
; PURECAP-NEXT:    cmp w0, w1, uxth
; PURECAP-NEXT:    b.ne .LBB7_3
; PURECAP-NEXT:  // %bb.1: // %cmpxchg.trystore
; PURECAP-NEXT:    stlxrh w8, w2, [c3]
; PURECAP-NEXT:    cbz w8, .LBB7_4
; PURECAP-NEXT:  // %bb.2: // %cmpxchg.failure
; PURECAP-NEXT:    mov w1, wzr
; PURECAP-NEXT:    // kill: def $w0 killed $w0 killed $x0
; PURECAP-NEXT:    ret c30
; PURECAP-NEXT:  .LBB7_3: // %cmpxchg.nostore
; PURECAP-NEXT:    clrex
; PURECAP-NEXT:    mov w1, wzr
; PURECAP-NEXT:    // kill: def $w0 killed $w0 killed $x0
; PURECAP-NEXT:    ret c30
; PURECAP-NEXT:  .LBB7_4:
; PURECAP-NEXT:    mov w1, #1
; PURECAP-NEXT:    // kill: def $w0 killed $w0 killed $x0
; PURECAP-NEXT:    ret c30
;
; HYBRID-LABEL: test_cmpxchg_weak_i16:
; HYBRID:       // %bb.0:
; HYBRID-NEXT:    stp x30, x19, [sp, #-16]! // 16-byte Folded Spill
; HYBRID-NEXT:    mov w19, w1
; HYBRID-NEXT:    bl __sync_val_compare_and_swap_2_c
; HYBRID-NEXT:    cmp w0, w19, uxth
; HYBRID-NEXT:    cset w1, eq
; HYBRID-NEXT:    ldp x30, x19, [sp], #16 // 16-byte Folded Reload
; HYBRID-NEXT:    ret
  %1 = cmpxchg weak i16 addrspace(200)* %ptr, i16 %exp, i16 %new acq_rel acquire
  ret { i16, i1 } %1
}

define { i32, i1 } @test_cmpxchg_weak_i32(i32 addrspace(200)* %ptr, i32 %exp, i32 %new) nounwind {
; PURECAP-LABEL: test_cmpxchg_weak_i32:
; PURECAP:       .Lfunc_begin8:
; PURECAP-NEXT:  // %bb.0: // %cmpxchg.start
; PURECAP-NEXT:    mov c3, c0
; PURECAP-NEXT:    ldaxr w0, [c0]
; PURECAP-NEXT:    cmp w0, w1
; PURECAP-NEXT:    b.ne .LBB8_3
; PURECAP-NEXT:  // %bb.1: // %cmpxchg.trystore
; PURECAP-NEXT:    stlxr w8, w2, [c3]
; PURECAP-NEXT:    cbz w8, .LBB8_4
; PURECAP-NEXT:  // %bb.2: // %cmpxchg.failure
; PURECAP-NEXT:    mov w1, wzr
; PURECAP-NEXT:    // kill: def $w0 killed $w0 killed $x0
; PURECAP-NEXT:    ret c30
; PURECAP-NEXT:  .LBB8_3: // %cmpxchg.nostore
; PURECAP-NEXT:    clrex
; PURECAP-NEXT:    mov w1, wzr
; PURECAP-NEXT:    // kill: def $w0 killed $w0 killed $x0
; PURECAP-NEXT:    ret c30
; PURECAP-NEXT:  .LBB8_4:
; PURECAP-NEXT:    mov w1, #1
; PURECAP-NEXT:    // kill: def $w0 killed $w0 killed $x0
; PURECAP-NEXT:    ret c30
;
; HYBRID-LABEL: test_cmpxchg_weak_i32:
; HYBRID:       // %bb.0:
; HYBRID-NEXT:    stp x30, x19, [sp, #-16]! // 16-byte Folded Spill
; HYBRID-NEXT:    mov w19, w1
; HYBRID-NEXT:    bl __sync_val_compare_and_swap_4_c
; HYBRID-NEXT:    cmp w0, w19
; HYBRID-NEXT:    cset w1, eq
; HYBRID-NEXT:    ldp x30, x19, [sp], #16 // 16-byte Folded Reload
; HYBRID-NEXT:    ret
  %1 = cmpxchg weak i32 addrspace(200)* %ptr, i32 %exp, i32 %new acq_rel acquire
  ret { i32, i1 } %1
}

define { i64, i1 } @test_cmpxchg_weak_i64(i64 addrspace(200)* %ptr, i64 %exp, i64 %new) nounwind {
; PURECAP-LABEL: test_cmpxchg_weak_i64:
; PURECAP:       .Lfunc_begin9:
; PURECAP-NEXT:  // %bb.0: // %cmpxchg.start
; PURECAP-NEXT:    mov c3, c0
; PURECAP-NEXT:    ldaxr x0, [c0]
; PURECAP-NEXT:    cmp x0, x1
; PURECAP-NEXT:    b.ne .LBB9_3
; PURECAP-NEXT:  // %bb.1: // %cmpxchg.trystore
; PURECAP-NEXT:    stlxr w8, x2, [c3]
; PURECAP-NEXT:    cbz w8, .LBB9_4
; PURECAP-NEXT:  // %bb.2: // %cmpxchg.failure
; PURECAP-NEXT:    mov w1, wzr
; PURECAP-NEXT:    ret c30
; PURECAP-NEXT:  .LBB9_3: // %cmpxchg.nostore
; PURECAP-NEXT:    clrex
; PURECAP-NEXT:    mov w1, wzr
; PURECAP-NEXT:    ret c30
; PURECAP-NEXT:  .LBB9_4:
; PURECAP-NEXT:    mov w1, #1
; PURECAP-NEXT:    ret c30
;
; HYBRID-LABEL: test_cmpxchg_weak_i64:
; HYBRID:       // %bb.0:
; HYBRID-NEXT:    stp x30, x19, [sp, #-16]! // 16-byte Folded Spill
; HYBRID-NEXT:    mov x19, x1
; HYBRID-NEXT:    bl __sync_val_compare_and_swap_8_c
; HYBRID-NEXT:    cmp x0, x19
; HYBRID-NEXT:    cset w1, eq
; HYBRID-NEXT:    ldp x30, x19, [sp], #16 // 16-byte Folded Reload
; HYBRID-NEXT:    ret
  %1 = cmpxchg weak i64 addrspace(200)* %ptr, i64 %exp, i64 %new acq_rel acquire
  ret { i64, i1 } %1
}

define { i8 addrspace(200)*, i1 } @test_cmpxchg_weak_cap(i8 addrspace(200)* addrspace(200)* %ptr, i8 addrspace(200)* %exp, i8 addrspace(200)* %new) nounwind {
; PURECAP-LABEL: test_cmpxchg_weak_cap:
; PURECAP:       .Lfunc_begin10:
; PURECAP-NEXT:  // %bb.0:
; PURECAP-NEXT:    mov c3, c1
; PURECAP-NEXT:    casal c3, c2, [c0]
; PURECAP-NEXT:    cmp x3, x1
; PURECAP-NEXT:    cset w1, eq
; PURECAP-NEXT:    mov c0, c3
; PURECAP-NEXT:    ret c30
;
; HYBRID-LABEL: test_cmpxchg_weak_cap:
; HYBRID:       // %bb.0:
; HYBRID-NEXT:    sub sp, sp, #32 // =32
; HYBRID-NEXT:    str x30, [sp, #16] // 8-byte Folded Spill
; HYBRID-NEXT:    str c1, [sp, #0] // 16-byte Folded Spill
; HYBRID-NEXT:    bl __sync_val_compare_and_swap_cap_c
; HYBRID-NEXT:    ldr c1, [sp, #0] // 16-byte Folded Reload
; HYBRID-NEXT:    ldr x30, [sp, #16] // 8-byte Folded Reload
; HYBRID-NEXT:    cmp x0, x1
; HYBRID-NEXT:    cset w1, eq
; HYBRID-NEXT:    add sp, sp, #32 // =32
; HYBRID-NEXT:    ret
  %1 = cmpxchg weak i8 addrspace(200)* addrspace(200)* %ptr, i8 addrspace(200)* %exp, i8 addrspace(200)* %new acq_rel acquire
  ret { i8 addrspace(200)*, i1 } %1
}

define { i32 addrspace(200)*, i1 } @test_cmpxchg_weak_cap_i32(i32 addrspace(200)* addrspace(200)* %ptr, i32 addrspace(200)* %exp, i32 addrspace(200)* %new) nounwind {
; PURECAP-LABEL: test_cmpxchg_weak_cap_i32:
; PURECAP:       .Lfunc_begin11:
; PURECAP-NEXT:  // %bb.0:
; PURECAP-NEXT:    mov c3, c1
; PURECAP-NEXT:    casal c3, c2, [c0]
; PURECAP-NEXT:    cmp x3, x1
; PURECAP-NEXT:    cset w1, eq
; PURECAP-NEXT:    mov c0, c3
; PURECAP-NEXT:    ret c30
;
; HYBRID-LABEL: test_cmpxchg_weak_cap_i32:
; HYBRID:       // %bb.0:
; HYBRID-NEXT:    sub sp, sp, #32 // =32
; HYBRID-NEXT:    str x30, [sp, #16] // 8-byte Folded Spill
; HYBRID-NEXT:    str c1, [sp, #0] // 16-byte Folded Spill
; HYBRID-NEXT:    bl __sync_val_compare_and_swap_cap_c
; HYBRID-NEXT:    ldr c1, [sp, #0] // 16-byte Folded Reload
; HYBRID-NEXT:    ldr x30, [sp, #16] // 8-byte Folded Reload
; HYBRID-NEXT:    cmp x0, x1
; HYBRID-NEXT:    cset w1, eq
; HYBRID-NEXT:    add sp, sp, #32 // =32
; HYBRID-NEXT:    ret
  %1 = cmpxchg weak i32 addrspace(200)* addrspace(200)* %ptr, i32 addrspace(200)* %exp, i32 addrspace(200)* %new acq_rel acquire
  ret { i32 addrspace(200)*, i1 } %1
}
